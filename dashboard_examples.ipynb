{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import * is safe: a restrictive __all__ has been defined in the modules\n",
    "from explainerdashboard.explainers import *\n",
    "from explainerdashboard.dashboards import *\n",
    "from explainerdashboard.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"Sex\": \"Gender of passenger\",\n",
    "    \"Deck\": \"The deck the passenger had their cabin on\",\n",
    "    \"PassengerClass\": \"The class of the ticket: 1st, 2nd or 3rd class\",\n",
    "    \"Fare\": \"The amount of money people paid\", \n",
    "    \"No_of_relatives_on_board\": \"number of siblings, spouses, parents plus children on board\",\n",
    "    \"Embarked\": \"the port where the passenger boarded the Titanic. Either Southampton, Cherbourg or Queenstown\",\n",
    "    \"Age\": \"Age of the passenger\",\n",
    "    \"No_of_siblings_plus_spouses_on_board\": \"The sum of the number of siblings plus the number of spouses on board\",\n",
    "    \"No_of_parents_plus_children_on_board\" : \"The sum of the number of parents plus the number of children on board\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClassifierExplainer examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier data:\n",
    "    - predicting probability that a person on the titanic survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = titanic_survive()\n",
    "train_names, test_names = titanic_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the passenger names later as idxs for the Explainer, such that they get displayed on the contributions tab of the dashboard, and you can also use them to pass as an index into various methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One line example:\n",
    "- click on the link (http://localhost:8050) to go to the dashboard\n",
    "- Interrupt the kernel to stop the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(ClassifierExplainer(RandomForestClassifier().fit(X_train, y_train), X_test, y_test)).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi line example\n",
    "- create an explainer object out the model and the X and y that you wish to display.\n",
    "- the explainer object calculates shap values, permutation importances, pdp's, etc, and provides all kinds of plots that will be used by the ExplainerDashboard object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = ClassifierExplainer(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an ExplainerDashboard instance out of the explainer instance:\n",
    "- depending on which tabs are included, all necessary calculations (shap values, importances, etc) get done up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ExplainerDashboard(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the dashboard on the default port (=8050):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or on another port, e.g. port 8051:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on specific port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(8051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch on/off specific tabs (+add title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all the tabs that should work are displayed, exceptions:\n",
    "- shap_interaction tab is disabled when model doesn't support shap interaction values\n",
    "    - e.g. linear models, or when calculating shap values in probability space for gradient boosting models\n",
    "- **Depending on your model and data calculating shap interaction values may be slow, so in that case switch off the interactions tab manually!**\n",
    "- decision_trees tab is disabled unless explainer is RandomForestClassifierExplainer or RandomForestRegressionExplainer\n",
    "\n",
    "- You can also manually switch tabs on or off with booleans, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(explainer, title=\"Titanic Explainer\",\n",
    "                        model_summary=True,  \n",
    "                        contributions=True,\n",
    "                        shap_dependence=False,\n",
    "                        shap_interaction=False,\n",
    "                        decision_trees=False).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cats, idxs, descriptions, labels\n",
    "\n",
    "You can make the dashboard a bit more user friendly by passing in some additional information about the variables in the model:\n",
    "\n",
    "- `cats`: If you have onehotencoded some variables, you get a lot of shap values for binary features that are either 0 or 1, which are hard to interpret as a whole. \n",
    "    - However, given that shap values are additive, we can sum them up and give a single shap value for the onehotencoded variables! \n",
    "    - Furthermore, we can use different types of default plots for categorical variables than continuous ones. \n",
    "    - By passing a list of variables that have been encoded with `varname_category` `explainerdashboard` will allow you to group the cats and show appropriate plots\n",
    "    - In our sample dataset this would be:\n",
    "        - `Sex`: `Sex_female`, `Sex_male` \n",
    "        - `Deck`: `Deck_A`, `Deck_B`, etc\n",
    "        - `Embarked`: `Embarked_Southampton`, `Embarked_Cherbourg`, etc\n",
    "- `idxs`: You may have specific identifiers (names, customer id's, etc) for each row in your dataset.\n",
    "    - If you pass these the the Explainer object, you can index using both the numerical index, e.g. `explainer.contrib_df(0)` for the first row, or using the identifier, e.g. `explainer.contrib_df(\"Braund, Mr. Owen Harris\")` \n",
    "    - The proper name or id will also be displayed and searchable on the contributions tab\n",
    "- `descriptions`: a dictionary of descriptions for each variable.\n",
    "    - In order to be explanatory, you often have to explain the meaning of the features themselves (especially if the naming is not obvious)\n",
    "    - Passing the dict along to `descriptions` will show hover-over tooltips for the various variables in the dashboard\n",
    "- `labels`: The outcome variables for a classification problem are assumed to be encoded 0, 1 (, 2, 3, ...)\n",
    "    - This is not very human readable, so you can pass a list of human readable labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ClassifierExplainer(model, X_test, y_test,\n",
    "                               cats=['Sex', 'Deck', 'Embarked'], # makes it easy to group onehotencoded vars\n",
    "                               idxs=test_names, #names of passengers # index by name\n",
    "                               descriptions=feature_descriptions, # show feature descriptions in plots\n",
    "                               labels=['Not survived', 'Survived']) # show nice labels\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also pass a title and explicitly switch off certain tabs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ExplainerDashboard(explainer, \"Titanic Explainer\",\n",
    "                        model_summary=True,\n",
    "                        contributions=False,\n",
    "                        shap_dependence=True,\n",
    "                        shap_interaction=False, # Linear models have no interactions\n",
    "                        decision_trees=False)\n",
    "db.run(8052)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_background, model_output and shap\n",
    "- `X_background`: \n",
    "    - Some models like LogisticRegression (as well as certain gradienst boosting algorithms in probability space) need a background dataset to calculate shap values. These can be passed as `X_background`.\n",
    "    - If you don't pass an `X_background`, Explainer uses X instead but gives off a warning.\n",
    "- `model_output`: \n",
    "    - By default model_output for classifier is set to \"probability\", as this is more intuitively explainable to non data scientist stakeholders\n",
    "    - However for certain models (e.g. XGBClassifier, LGBMCLassifier, CatBoostClassifier), need a background dataset X_background to calculate shap values in probability space, and are not able to calculate shap interaction values.\n",
    "    - Therefore you can also pass `model_output='logodds'`, in which case shap values get calculated as logodds\n",
    "- `shap`:\n",
    "    - By default `shap='guess'`, which means that the Explainer will try to guess based on the model what kind of shap explainer it needs: e.g. `shap.TreeExplainer(...)`, `shap.LinearExplainer(...)`, etc.\n",
    "    - In case the guess fails or you'd like to override it, you can set it manually:\n",
    "        - e.g. `shap='tree'`, `shap='linear'`, `shap='kernel'`, `shap='deep'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = ClassifierExplainer(model, X_test, y_test, \n",
    "                                    shap='linear', \n",
    "                                    X_background=X_train, \n",
    "                                    model_output='logodds')\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier, LGBMClassifier, CatBoostClassifier\n",
    "- default for ClassifierExplainer is `model_output='probability'`, but for most gradient boosting classifier algorithms (e.g xgboost, lightgbm, catboost):\n",
    "    - You have to pass an `X_background` to calculate the shape values against (defaults to using `X`)\n",
    "    - You can't calculate shap interaction values\n",
    "- alternative is to pass model_output='logodds':\n",
    "    - Can then calculate shap values based on trees alone (so no background data needed), and can calculate interaction values as well.\n",
    "    - plus: faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lightgbm.sklearn import LGBMClassifier\n",
    "#model = LGBMClassifier()\n",
    "\n",
    "#from catboost import CatBoostClassifier\n",
    "#model = CatBoostClassifier(iterations=100, learning_rate=100)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = ClassifierExplainer(model, X_test, y_test, \n",
    "                                    X_background=X_train,\n",
    "                                    cats=['Sex', 'Deck', 'Embarked'],\n",
    "                                    idxs=test_names, #names of passengers \n",
    "                                    labels=['Not survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ClassifierExplainer(model, X_test, y_test, \n",
    "                                    model_output='logodds', # <---------\n",
    "                                    cats=['Sex', 'Deck', 'Embarked'],\n",
    "                                    idxs=test_names, #names of passengers \n",
    "                                    labels=['Not survived', 'Survived'])\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegressionExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load regression data:\n",
    "    - predicting the fare that a titanic passenger paid for their ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = titanic_fare()\n",
    "train_names, test_names = titanic_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding units of target\n",
    "- In this case we are predicting the price of the fare, so we can add the units as `\"$\"`\n",
    "    - this will then be displayed along the axis of certain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = RegressionExplainer(model, X_test, y_test, \n",
    "                                cats=['Sex', 'Deck', 'Embarked'], \n",
    "                                idxs=test_names, \n",
    "                                units=\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRegressor, LinearRegression, CatBoostRegressor, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRegressor\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression()\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# model = CatBoostRegressor(iterations=100, learning_rate=0.1, verbose=0)\n",
    "\n",
    "# from xgboost import XGBRegressor\n",
    "# model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "explainer = RegressionExplainer(model, X_test, y_test, \n",
    "                                cats=['Sex', 'Deck', 'Embarked'], \n",
    "                                idxs=test_names, \n",
    "                                units=\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = titanic_class()\n",
    "train_names, test_names = titanic_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = ClassifierExplainer(model, X_test, y_test, \n",
    "                                    cats=['Sex', 'Deck', 'Embarked'],\n",
    "                                    idxs=test_names, \n",
    "                                    labels=['First Class', 'Second Class', ' Third Class'],\n",
    "                                    pos_label='First Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestsClassifierExplainer, RandomForestRegresionExplainer\n",
    "\n",
    "visualize individual decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, y_train, X_test, y_test = titanic_survive()\n",
    "train_names, test_names = titanic_names()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = RandomForestClassifierExplainer(model, X_test, y_test, \n",
    "                                    cats=['Sex', 'Deck', 'Embarked'],\n",
    "                                    idxs=test_names, \n",
    "                                    labels=['Not survived', 'Survived'])\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_train, y_train, X_test, y_test = titanic_fare()\n",
    "train_names, test_names = titanic_names()\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = RandomForestRegressionExplainer(model, X_test, y_test, \n",
    "                                cats=['Sex', 'Deck', 'Embarked'], \n",
    "                                idxs=test_names, \n",
    "                                units=\"$\")\n",
    "\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
